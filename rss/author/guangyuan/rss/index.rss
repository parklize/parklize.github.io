<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[Guangyuan Piao - Guangyuan Piao ]]></title><description><![CDATA[I'm Research Scientist at Bell Labs. I blog about Machine Learing, Deep Learning, and Network Management]]></description><link>http://localhost:2368/</link><image><url>http://localhost:2368/favicon.png</url><title>Guangyuan Piao - Guangyuan Piao </title><link>http://localhost:2368/</link></image><generator>Ghost 3.2</generator><lastBuildDate>Tue, 28 Apr 2020 22:10:26 GMT</lastBuildDate><atom:link href="http://localhost:2368/author/guangyuan/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[My User Modeling Slide in the Google Knowledge Graph]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>It is interesting to find out that my slide on the <a href="http://slideshare.net">slideshare</a> shows up on the Google Knowledge Graph when searching the term <strong>user modeling</strong> on <a href="https://google.com">Google</a>.</p>
<p><img src="http://localhost:2368/content/images/2018/12/UM.png" alt="UM"></p>
<!--kg-card-end: markdown-->]]></description><link>http://localhost:2368/my-user-modeling-slide-in-the-google-knowledge-graph/</link><guid isPermaLink="false">5e09207482f7780f240f272f</guid><dc:creator><![CDATA[Guangyuan Piao]]></dc:creator><pubDate>Mon, 17 Dec 2018 23:25:18 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p>It is interesting to find out that my slide on the <a href="http://slideshare.net">slideshare</a> shows up on the Google Knowledge Graph when searching the term <strong>user modeling</strong> on <a href="https://google.com">Google</a>.</p>
<p><img src="http://localhost:2368/content/images/2018/12/UM.png" alt="UM"></p>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Topic: Anomaly Detection]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p><strong>Anomaly Detection</strong> is a data analysis task which detects anomalies from a given dataset is important in many contexts and domains such as medical and health, fraud detection in finance, and computer systems &amp; networks <sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>. The same problem has also been terms as:</p>
<ul>
<li>outlier detection</li>
<li>novelty detection</li>
<li>deviation detection</li></ul>]]></description><link>http://localhost:2368/anomaly-detection/</link><guid isPermaLink="false">5e09207482f7780f240f272e</guid><category><![CDATA[topic]]></category><category><![CDATA[research]]></category><category><![CDATA[post]]></category><dc:creator><![CDATA[Guangyuan Piao]]></dc:creator><pubDate>Wed, 05 Dec 2018 23:01:24 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p><strong>Anomaly Detection</strong> is a data analysis task which detects anomalies from a given dataset is important in many contexts and domains such as medical and health, fraud detection in finance, and computer systems &amp; networks <sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>. The same problem has also been terms as:</p>
<ul>
<li>outlier detection</li>
<li>novelty detection</li>
<li>deviation detection</li>
<li>exception mining</li>
</ul>
<h2 id="definitionofanomaly">Definition of Anomaly</h2>
<p><em>Anomalies</em> denote patterns that do not conform expected behavior, and hav e been refered to as other terms such as <em>outliers</em>, <em>discordant observations</em>, <em>exceptions</em>, <em>aberrations</em>, <em>surprises</em>, <em>peculiarities</em> or <em>contaminants</em> in different application domains <sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>. Among many definitions in the literature, one of the widely accepted definition of anomaly by Hawkins <sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup> is defined as follows.</p>
<blockquote>
<p>An anomaly is an observation which deviates so much from other observations as to arouse suspicions that it was generated by a different mechanism.</p>
</blockquote>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- parklize_main_Blog1_728x90_as -->
<p><ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-9673038949803914" data-ad-slot="4115851559"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2 id="relationshipstonoisenovelty">Relationships to <em>noise</em> &amp; <em>novelty</em></h2>
<p>The key distinction between a <em>noise</em> and <em>anomaly</em> is the interestingness of the pattern to the analyst. Noise is not of interest to the analyst while anomaly is.</p>
<p>The distinction between novel patterns and anomaly ones is that the novel patterns are typically incorporated into the normal model after being detected <sup class="footnote-ref"><a href="#fn2" id="fnref2:1">[2:1]</a></sup>.</p>
<h2 id="typesofanomalies">Types of Anomalies</h2>
<p>Usually, anomalies can be categorized into three main types <sup class="footnote-ref"><a href="#fn1" id="fnref1:1">[1:1]</a></sup><sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>:</p>
<ul>
<li>
<p><strong>Point Anomalies</strong>: A point anomaly is any point which deviates from the range of expected values in a given dataset. For example, a memory usage value which has 3 standard deviation from the mean can be considered as a point anomaly. The majority of previous studies has been focused on point anomalies.</p>
</li>
<li>
<p><strong>Collective Anomalies</strong>: A homogeneous group/set of data points deviating from the normal <em>regions</em> of the rest of the data. For example, an unexpected streak of low throughput values may be considered as collective anomalies when compared with higher ones in the past observation window.</p>
</li>
<li>
<p><strong>Contextual Anomalies</strong>: Anomalies that manifest only under certain environments/contexts. For example, high expenditure during a festive period can be considered as normal in the context, e.g., black friday. Contextual anomalies require that the data has a set of <em>contextual attributes</em> (to define a context), and a set of <em>behavior attributes</em> (to detect anomalies within a context).</p>
</li>
<li>
<p><strong>Pattern Anomalies</strong>: The shapes of some performance metrics when plotted are know to exhibit specific pattern, and the violation of this can be considered as pattern anomalies. This can be seen as a special case of collective anomalies.</p>
</li>
</ul>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- parklize_main_Blog1_728x90_as -->
<p><ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-9673038949803914" data-ad-slot="4115851559"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-9673038949803914",
          enable_page_level_ads: true
     });
</script>
<h2 id="inputoutput">Input &amp; Output</h2>
<ul>
<li><strong>Input</strong>: a set of data instances where each data instance can be described using a set of attributes. Each data instance can be <em>univariate</em> (one attribute) or <em>multivariate</em> (multiple attributes).</li>
<li><strong>Output</strong>: labels and/or scores. Scoring mechanisom allows analyst to use a domain specific threshold to filter relevant anomalies.</li>
</ul>
<h2 id="typesofsolutionswithrespecttolabelconditions">Types of Solutions with respect to Label Conditions</h2>
<p>Based on the availability of the labels associated with data instances, anomaly detection techniques can be categorized into three types <sup class="footnote-ref"><a href="#fn2" id="fnref2:2">[2:2]</a></sup>:</p>
<ul>
<li><strong>Supervised Anomaly Detection</strong>: It assumes labeled training set is available, which is not always the case. In addition, even it is availble, the numbers of anomaly and non-anomaly labels are imbalanced.</li>
<li><strong>Semisupervised Anomaly Detection</strong>: It assumes that we have a training set with the normal class. A typical approach in this stream is to build a model for the normal class, and use it to identify anomalies in the test data.</li>
<li><strong>Unsupervised Anomaly Detection</strong>: No need for training data, and thus is widely applicable. It assumes that normal instances are far more frequent than anomalies in the test data.</li>
</ul>
<h2 id="references">References</h2>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Ahmed, Mohiuddin, Abdun Naser Mahmood, and Jiankun Hu. &quot;A survey of network anomaly detection techniques.&quot; Journal of Network and Computer Applications 60 (2016): 19-31. <a href="#fnref1" class="footnote-backref">↩︎</a> <a href="#fnref1:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>Chandola, Varun, Arindam Banerjee, and Vipin Kumar. &quot;Anomaly detection: A survey.&quot; ACM computing surveys (CSUR) 41.3 (2009): 15. <a href="#fnref2" class="footnote-backref">↩︎</a> <a href="#fnref2:1" class="footnote-backref">↩︎</a> <a href="#fnref2:2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p>Hawkins, Douglas M. Identification of outliers. Vol. 11. London: Chapman and Hall, 1980. <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p>Ibidunmoye, Olumuyiwa, Francisco Hernández-Rodriguez, and Erik Elmroth. &quot;Performance anomaly detection and bottleneck identification.&quot; ACM Computing Surveys (CSUR) 48.1 (2015): 4. <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Curated Research Advice]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>As the majority of us is doing PhD for the first time, we experience many obstacles before/during/after the PhD life. Sometimes, I thought it would be great to know many things at that time before I starting my PhD. Here is a list of curated research advice during</p>]]></description><link>http://localhost:2368/curated-research-advice/</link><guid isPermaLink="false">5e09207482f7780f240f272d</guid><dc:creator><![CDATA[Guangyuan Piao]]></dc:creator><pubDate>Mon, 26 Nov 2018 23:35:33 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p>As the majority of us is doing PhD for the first time, we experience many obstacles before/during/after the PhD life. Sometimes, I thought it would be great to know many things at that time before I starting my PhD. Here is a list of curated research advice during my PhD, which might be useful for many students who are going to do, doing or going to finish their PhD degrees. It ocovers the topics such as:</p>
<ul>
<li>research life/career (PhD &amp; after PhD)</li>
<li>writing, reading &amp; reviewing research papers</li>
<li>thesis &amp; defense!</li>
</ul>
<div style="text-align:left" id="ly_wrap_1tIf"><script type="text/javascript" src="https://list.ly/plugin/show?list=1tIf&layout=full&per_page=25"></script></div><!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Machine & Deep Learning for Network Management: An Overview with Benchmarks]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>This post gives a general overview of the set of tasks with respect to the networking with machine learning and deep learning, and provide a list of benchmark datasets that can play with for networking.</p>
<h1 id="introduction">Introduction</h1>
<p>Machine learning &amp; deep learning techniques have advanced many fields such as Computer Vision</p>]]></description><link>http://localhost:2368/machine-deep-learning-for-network-management-an-overview/</link><guid isPermaLink="false">5e09207482f7780f240f272c</guid><category><![CDATA[post]]></category><category><![CDATA[network]]></category><category><![CDATA[management]]></category><category><![CDATA[resource]]></category><category><![CDATA[deep learning]]></category><category><![CDATA[machine learning]]></category><dc:creator><![CDATA[Guangyuan Piao]]></dc:creator><pubDate>Fri, 26 Oct 2018 21:45:53 GMT</pubDate><media:content url="http://localhost:2368/content/images/2018/11/label-text-network-computer-hardware-cpu-electronic-chip-electronics-h.jpg" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><img src="http://localhost:2368/content/images/2018/11/label-text-network-computer-hardware-cpu-electronic-chip-electronics-h.jpg" alt="Machine & Deep Learning for Network Management: An Overview with Benchmarks"><p>This post gives a general overview of the set of tasks with respect to the networking with machine learning and deep learning, and provide a list of benchmark datasets that can play with for networking.</p>
<h1 id="introduction">Introduction</h1>
<p>Machine learning &amp; deep learning techniques have advanced many fields such as Computer Vision (CV) and Natural Language Processing (NLP), and also have been embedded in our daily lives, e.g., classifying images, facial recognition, and recommending items in Amazon<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> or Netflix<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>.The following figure from Fadlullah et al. <sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup> provides a good summary of different machine learning techniques and their applications.</p>
<img src="http://localhost:2368/content/images/2018/10/ML.png" alt="Machine & Deep Learning for Network Management: An Overview with Benchmarks" width="100%">
<p> </p>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- parklize_main_Blog1_728x90_as -->
<p><ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-9673038949803914" data-ad-slot="4115851559"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>In the networking community, there has been many proposals to explore machine/deep learning for controlling and operating networks. <strong>Knowledge Plane (KP)</strong> <sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup> is one of the first proposals to incorporate a knowledge plane, which relies on machine learning and cognitive techniques for network management &amp; operations. More recently, <strong>Knowledge-Defined Networking (KDN)</strong> <sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup> restaed the concept of KP in the context of the Software-Defined Networking (SDN), which can provide a centralized control with a rich view of the network via network analytics.</p>
<p>On the one hand, recent advances of networking technologies such as SDN, Network Function Virtualization (NFV) and Telemetry provide unique opportunities for adopting machine/deep learning techniques with the huge amount of data we can gather with a centralized view &amp; control. On the other hand, the growing complexity of future networks which cannot be handled by simple heuristics and human, also requires the help of machine/deep learning approaches for automation as well as recommendations for network control, operations and management.</p>
<p>In line with the KDN vision, there has been many surveys discussing challenges, opportunities with promising problems that can be dealt with machine/deep learning approaches <sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup><sup class="footnote-ref"><a href="#fn3" id="fnref3:1">[3:1]</a></sup><sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup><sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup><sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup><sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup><sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup><sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup><sup class="footnote-ref"><a href="#fn13" id="fnref13">[13]</a></sup><sup class="footnote-ref"><a href="#fn14" id="fnref14">[14]</a></sup><sup class="footnote-ref"><a href="#fn15" id="fnref15">[15]</a></sup><sup class="footnote-ref"><a href="#fn16" id="fnref16">[16]</a></sup>. The following summaries for each survey might be useful as a pointer for each survey if the reader wants to delve into details.</p>
<ul>
<li><sup class="footnote-ref"><a href="#fn6" id="fnref6:1">[6:1]</a></sup> - Defined <strong>the workflow of machine learning for networking</strong> &amp; provided an overview of the studies based on the workflow.</li>
<li><sup class="footnote-ref"><a href="#fn3" id="fnref3:2">[3:2]</a></sup> - Review of deep learning approaches for <strong>network traffic control</strong>.</li>
<li><sup class="footnote-ref"><a href="#fn7" id="fnref7:1">[7:1]</a></sup> - Brief oerview of <a href="http://www.ciscopress.com/store/network-management-fundamentals-9781587052804">FCAPS (Fault, Configuration, Accounting, Performance, Security) management</a>, and a proposal of C-MAPE: a concept of cognitive control loop for network management on top of MAPE (Monitor-Analyze-Plan-Excute <sup class="footnote-ref"><a href="#fn17" id="fnref17">[17]</a></sup>).</li>
<li><sup class="footnote-ref"><a href="#fn9" id="fnref9:1">[9:1]</a></sup> - Deep learning vision for <strong>network traffic control</strong>.</li>
<li><sup class="footnote-ref"><a href="#fn10" id="fnref10:1">[10:1]</a></sup> - Detailed overview of recent AI (Artificial Intelligence not only machine learning) approaches applied to <strong>the SDN paradigm</strong>.</li>
<li><sup class="footnote-ref"><a href="#fn11" id="fnref11:1">[11:1]</a></sup> - Review of <strong>unsupervised learning</strong> for networking.</li>
<li><sup class="footnote-ref"><a href="#fn13" id="fnref13:1">[13:1]</a></sup><sup class="footnote-ref"><a href="#fn12" id="fnref12:1">[12:1]</a></sup> - Overview of AI techniques &amp; taxonomies for <a href="#son">SON (Self-Organizing Networks)</a></li>
<li><sup class="footnote-ref"><a href="#fn15" id="fnref15:1">[15:1]</a></sup> - Review of AI techniques for <strong>cognitive routing</strong>.</li>
<li><sup class="footnote-ref"><a href="#fn16" id="fnref16:1">[16:1]</a></sup> - Review and provide taxonomy of cloud <strong>autoscaling</strong> systems</li>
<li><sup class="footnote-ref"><a href="#fn14" id="fnref14:1">[14:1]</a></sup> - Comprehensive survey on machine learning for networking problems (the most comprehensive/longest one with 500+ references).</li>
</ul>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- parklize_main_Blog1_728x90_as -->
<p><ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-9673038949803914" data-ad-slot="4115851559"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-9673038949803914",
          enable_page_level_ads: true
     });
</script>
<h1 id="machinedeeplearningtasksfornetworkmanagement">Machine &amp; Deep Learning Tasks for Network Management</h1>
<p>This section provides an overview of different tasks that machine/deep learning approaches can be applied in the networking domain based on these recent surveys &amp; reviews.</p>
<h3 id="supervisedlearningproblems">Supervised Learning Problems</h3>
<p>Many problems associated to networking can be formulated as a <em>prediction</em> or <em>classification</em> problem.</p>
<p><strong>Traffic prediction</strong>: Depends on whether the traffic prediction is performed with direct observations or not, there are two research directions:</p>
<ul>
<li>
<p><em>Time series analysis</em> for traffic prediction with direct observations. However, it is sometimes difficult to observe in the context of large-scale and high speed network environment.</p>
</li>
<li>
<p><a href="https://netbeez.net/blog/network-tomography/"><em>Network tomography</em></a> which predicts traffic using indirect metrics either (1) with engineered features with domain knowledge or (2) using machine/deep learning approaches for end-to-end learning, i.e., learning high-level features automatically.</p>
</li>
</ul>
<p><strong>Traffic classification</strong>: This aims to match network applications &amp; protocols with the corresponding traffic flows <sup class="footnote-ref"><a href="#fn18" id="fnref18">[18]</a></sup>. As the misclassfication causes a big cost in the context of networking, it is challenging to deal with robustness such as how the devised model performs on unknown traffic.</p>
<p><strong>Resource prediction</strong>: In order to improve the network performance in a cost efficent way, there are many dynamic allocation problems to deal with such as assigning optimal number of Virtual Machines (VMs). The fundamental step is predicting resource usage, e.g., predicting the CPU consumption based on traffic features.</p>
<p><strong>Network performance prediction</strong>: Similar to the abovementioned prediction problems, there are many prediction problems associated to network performance such as video QoE (Quality of Experience).</p>
<h3 id="reinforcementlearning">Reinforcement Learning</h3>
<p>Reinforcement learning deals with agents which learn to make better decisions through experience, i.e., the agents start without any knowledge about a task and learn the corresponding model of the task by reinforcement - the actions they take and the reward they get with these actions <sup class="footnote-ref"><a href="#fn19" id="fnref19">[19]</a></sup>.</p>
<p><strong>Resource management</strong>: This type of problems is ubiquitous in networking such as virtual machine placement &amp; autoscaling in cloud computing <sup class="footnote-ref"><a href="#fn20" id="fnref20">[20]</a></sup> and packing tasks with multiple resource demands <sup class="footnote-ref"><a href="#fn19" id="fnref19:1">[19:1]</a></sup>.</p>
<p><strong>Self-Organizing Netowrks (SON)</strong> <sup class="footnote-ref"><a href="#fn21" id="fnref21">[21]</a></sup>: With the increasing topological and functional complexity of networks, <em>Self-Organizing Networks</em> is in demand for network control and operations. SON consists of all <a name="son"><em>Self-X</em></a>  capabilities such as:</p>
<ul>
<li><em>Self-Configuration</em> of system parameters with changing environment</li>
<li><em>Self-Optimization</em> of the network performance</li>
<li><em>Self-Healing</em> of the system, i.e., recovering network functionalities &amp; services after fault or failures</li>
</ul>
<h3 id="unsupervisedlearning">Unsupervised Learning</h3>
<p>There are many situations that we do not have labeled data for supervised learning or it is impractical to wait for feedback for reinforcement learning. Unsupervised learning aims to infer representations from data that has not been labeled, classified or categorized. These representations can be used for many downstream tasks such as clustering, or improving the performance of related supervised learning tasks. In contrast to the amount of works done with supervised learning and reinforcement learning for different problems in the networking field, unsupervised learning has been less explored in this field <sup class="footnote-ref"><a href="#fn11" id="fnref11:2">[11:2]</a></sup>.</p>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- parklize_main_Blog1_728x90_as -->
<p><ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-9673038949803914" data-ad-slot="4115851559"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>However, unsupervised learning has gained a lot of attention and successfully advancing other fields such as NLP. For example, word2vec <sup class="footnote-ref"><a href="#fn22" id="fnref22">[22]</a></sup> in NLP clearly shows the latent representations of words which are pre-trained (or learned via an unsupervised learning approach) with a large corpus of documents (e.g., <a href="https://en.wikipedia.org/wiki/Main_Page">Wikipedia</a> can be used for many downstream tasks such as document clustering and sentiment classification.</p>
<p><strong>Learing internal representations of networking data</strong>: COMANETS (COgnition-BAsed NETworkS) <sup class="footnote-ref"><a href="#fn21" id="fnref21:1">[21:1]</a></sup> is a recent concept for leveraging unsupervised learning (using Restricted Boltzmann Machine) to learn the latent representations of networking data. A practical example using the COMANETS concept for cognitive controlling video traffic shows that using the latent representations can improve the control performance compared to the raw networking features.</p>
<p>The following figure shows the COMPANETS concept <sup class="footnote-ref"><a href="#fn21" id="fnref21:2">[21:2]</a></sup>. Similar to the word vectors (latent representations or embeddings) in NLP, the latent representations of networking data can be used for many downstream tasks along with supervised learning &amp; reinforcement learning.</p>
<img src="http://localhost:2368/content/images/2018/10/aa1.png" alt="Machine & Deep Learning for Network Management: An Overview with Benchmarks" width="80%">
<p><strong>Traffic Classification</strong>: Although the majority of previous studies for traffic classification is based on supervised learning approaches, leveraging completely unsupervised methods for traffic classification is an ongoing research topic <sup class="footnote-ref"><a href="#fn11" id="fnref11:3">[11:3]</a></sup>.</p>
<p><strong>Anomaly/Intrusion Detection</strong>: Identifying intrusion and anomaly behavior that deviates from normal behavior plays important role in networking with respec to its performance as well as security. Anomaly/Intrusion Detection can be done either in a supervised or unsupervised manner <sup class="footnote-ref"><a href="#fn23" id="fnref23">[23]</a></sup>.</p>
<p> </p>
<h3 id="decisionmaking">Decision Making</h3>
<p>The objective of leveraging abovementioned techniques is to make a decision either completely automatically or to help humans make decisions. Depends on whether there is human involvement or not, the decision making can be done in a (1) <strong>closed loop</strong> or (2) <strong>open loop</strong>. The following figure from <sup class="footnote-ref"><a href="#fn5" id="fnref5:1">[5:1]</a></sup> summarizes the three types of machine learning approaches in terms of decision making.</p>
<img src="http://localhost:2368/content/images/2018/10/aa-2.png" alt="Machine & Deep Learning for Network Management: An Overview with Benchmarks" width="60%">
<p> <br>
<strong>Closed loop</strong>: The models learned from supervised learning or reinforcement learning can be directly used for <em>automation</em> and making decisions by itself without any human (e.g., operator) involvement. The models can also be used for <em>optimizing</em> the network configuration out of different possible configurations based on the corresponding performance. The knowledge extracted via unsupervised learning can be used for improving other tasks with respect to networking.</p>
<p><strong>Open loop</strong>: In this case, human is still in charge of making the final decision, and the insight (e.g., predicted values, classes etc.) helps humans to make the decision. For example, a human can <em>validate</em> and then approve/deny the decisions made by a model learned via supervised learning, or use the <em>estimation</em> of the model into consideration. Similarly, the correlations between different features can be taken into consideration when a human making decision.</p>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- parklize_main_Blog1_728x90_as -->
<p><ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-9673038949803914" data-ad-slot="4115851559"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1 id="benchmarkdatasets">Benchmark Datasets</h1>
<p>Given the recent rapid development of machine &amp; deep learning in other domains with benchmark datasets such as <a href="http://www.image-net.org/">ImageNet</a> for Computer Vision &amp; the ones (<a href="http://nlpprogress.com/">http://nlpprogress.com/</a>) for Natural Language Processing, it is obvious that we need to push hard to have many benchmarks available for advancing machine &amp; deep learning approaches in the networking domain<sup class="footnote-ref"><a href="#fn6" id="fnref6:2">[6:2]</a></sup>. In the following table, we summarize some benchmark datasets that are publicly available for benchmarking different machine/deep learning algorithms.</p>
<h3 id="prediction">Prediction</h3>
<table>
<thead>
<tr>
<th>Dataset                         </th>
<th>Description                         </th>
<th style="text-align:center">Ref.                        </th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://knowledgedefinednetworking.org">VNF (OVS)</a></td>
<td>predicting CPU consumption of an OVS connected to a SDN controller with respect to 86 traffic features</td>
<td style="text-align:center"><sup class="footnote-ref"><a href="#fn5" id="fnref5:2">[5:2]</a></sup></td>
</tr>
<tr>
<td><a href="http://knowledgedefinednetworking.org">VNF (Firewall)</a></td>
<td>predicting CPU consumption of a Firewall connected to a SDN controller with respect to 86 traffic features</td>
<td style="text-align:center"><sup class="footnote-ref"><a href="#fn5" id="fnref5:3">[5:3]</a></sup></td>
</tr>
<tr>
<td><a href="http://knowledgedefinednetworking.org">VNF (Snort)</a></td>
<td>predicting CPU consumption of a Snort connected to a SDN controller with respect to 86 traffic features</td>
<td style="text-align:center"><sup class="footnote-ref"><a href="#fn5" id="fnref5:4">[5:4]</a></sup></td>
</tr>
<tr>
<td><a href="http://knowledgedefinednetworking.org">Overlay-Underlay</a></td>
<td>predicting the average delays among paths between overlay nodes given the traffic volumn &amp; the rounting</td>
<td style="text-align:center"><sup class="footnote-ref"><a href="#fn5" id="fnref5:5">[5:5]</a></sup></td>
</tr>
<tr>
<td><a href="http://knowledgedefinednetworking.org/">Routing</a></td>
<td>knowledgedefinedneFlow-level delay in a scale-free network with 4 different routings</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td><a href="http://knowledgedefinednetworking.org/">Saturation</a></td>
<td>Delay among pairs of nodes in a 10-nodes scale-free network changing the traffic intensity and traffic distribution</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td><a href="http://knowledgedefinednetworking.org/">NetSize</a></td>
<td>Delay among pairs of nodes in a 5, 10 and 15 nodes scale-free network.</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td><a href="http://knowledgedefinednetworking.org/">Topologies</a></td>
<td>Delay among pairs of nodes in different topologies and sizes.</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td><a href="https://github.com/wsdream/wsdream-dataset">WS-DREAM</a></td>
<td>QoS datasets  collected from real-world Web services.</td>
<td style="text-align:center"><sup class="footnote-ref"><a href="#fn24" id="fnref24">[24]</a></sup></td>
</tr>
</tbody>
</table>
<h3 id="classification">Classification</h3>
<table>
<thead>
<tr>
<th>Dataset                         </th>
<th>Description                        </th>
<th>Ref.                          </th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://mawi.wide.ad.jp/mawi/">MAWI</a></td>
<td>MAWI Working Group Traffic Archive</td>
<td><sup class="footnote-ref"><a href="#fn25" id="fnref25">[25]</a></sup></td>
</tr>
<tr>
<td><a href="https://wand.net.nz/wits/">WITS</a></td>
<td>Waikato Internet Traffic Storage</td>
<td></td>
</tr>
<tr>
<td><a href="http://www.icir.org/enterprise-tracing/">LBNL/ICSI</a></td>
<td>LBNL/ICSI Enterprise Tracing Project</td>
<td></td>
</tr>
<tr>
<td><a href="http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html">KDD99</a></td>
<td>Classifying <em>intrusion</em> &amp; <em>normal</em> connection</td>
<td></td>
</tr>
<tr>
<td><a href="https://www.neteye-blog.com/netcla-the-ecml-pkdd-network-classification-challenge/">NetCla</a></td>
<td>NetCla: The ECML-PKDD Network Classification Challenge</td>
<td></td>
</tr>
</tbody>
</table>
<p> <br>
I hope you found this overview useful. If I made any error, missed a relevant reference &amp; dataset, or misrepresented some aspect, or if you would just like to share your thoughts, please leave a comment below.</p>
<p>In case you would like to refer the post, consider citing it as:</p>
<blockquote>
<p>Guangyuan Piao (2018). &quot;Machine &amp; Deep Learning for Network Management: An Overview with Benchmarks&quot;. <a href="https://goo.gl/gp7gBb">https://goo.gl/gp7gBb</a></p>
</blockquote>
<pre><code>@misc{piao2018b1,
  author = {Piao, Guangyuan},
  title = {Machine &amp; Deep Learning for Network Management: An Overview with Benchmarks},
  year = {2018},
  howpublished = {Blog post},
  url = {https://goo.gl/gp7gBb}
}
</code></pre>
<h1 id="references">References</h1>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p><a href="https://www.wired.com/2016/05/amazons-giving-away-ai-behind-product-recommendations/">Amazon's Giving Away the AI Behind Its Product Recommendations (2016)</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>Gomez-Uribe, Carlos A. and Hunt, Neil, &quot;The Netflix Recommender System: Algorithms, Business Value, and Innovation. ACM Transactions on Management Information Systems&quot;, <a href="https://dl.acm.org/citation.cfm?id=2843948">https://dl.acm.org/citation.cfm?id=2843948</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p>Fadlullah, Zubair et al. &quot;State-of-the-Art Deep Learning: Evolving Machine Intelligence Toward Tomorrow’s Intelligent Network Traffic Control Systems&quot; (2017). <a href="https://doi.org/10.1109/COMST.2017.2707140">https://doi.org/10.1109/COMST.2017.2707140</a> <a href="#fnref3" class="footnote-backref">↩︎</a> <a href="#fnref3:1" class="footnote-backref">↩︎</a> <a href="#fnref3:2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p>A knowledge plane for the internet (2003). SIGCOMM. <a href="http://doi.acm.org/10.1145/863955.863957">http://doi.acm.org/10.1145/863955.863957</a> <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p>Clark, David D. et al. &quot;Knowledge-Defined Networking&quot; (2016). SIGCOMM Reivew. <a href="https://arxiv.org/pdf/1606.06222.pdf">https://arxiv.org/pdf/1606.06222.pdf</a> <a href="#fnref5" class="footnote-backref">↩︎</a> <a href="#fnref5:1" class="footnote-backref">↩︎</a> <a href="#fnref5:2" class="footnote-backref">↩︎</a> <a href="#fnref5:3" class="footnote-backref">↩︎</a> <a href="#fnref5:4" class="footnote-backref">↩︎</a> <a href="#fnref5:5" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn6" class="footnote-item"><p>Wang, Mowei et al. &quot;Machine Learning for Networking: Workflow, Advances and Opportunities&quot; (2017). IEEE Network. <a href="https://arxiv.org/pdf/1709.08339.pdf">https://arxiv.org/pdf/1709.08339.pdf</a> <a href="#fnref6" class="footnote-backref">↩︎</a> <a href="#fnref6:1" class="footnote-backref">↩︎</a> <a href="#fnref6:2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn7" class="footnote-item"><p>Ayoubi, S &quot;Machine Learning for Cognitive Network Management&quot; (2018).  IEEE Communications Magazine. <a href="https://doi.org/10.1109/MCOM.2018.1700560">https://doi.org/10.1109/MCOM.2018.1700560</a> <a href="#fnref7" class="footnote-backref">↩︎</a> <a href="#fnref7:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn8" class="footnote-item"><p>Hyun, N. Van Tu and J. W. Hong, &quot;Towards knowledge-defined networking using in-band network telemetry&quot; (2018). IEEE/IFIP Network Operations and Management Symposium. <a href="https://doi.org/10.1109/NOMS.2018.8406169">https://doi.org/10.1109/NOMS.2018.8406169</a> <a href="#fnref8" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn9" class="footnote-item"><p>Kato, Nei, et al. &quot;The deep learning vision for heterogeneous network traffic control: Proposal, challenges, and future perspective.&quot; IEEE wireless communications 24.3 (2017): 146-153. <a href="https://doi.org/10.1109/MWC.2016.1600317WC">https://doi.org/10.1109/MWC.2016.1600317WC</a> <a href="#fnref9" class="footnote-backref">↩︎</a> <a href="#fnref9:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn10" class="footnote-item"><p>Latah, Majd, and Levent Toker. &quot;Artificial Intelligence Enabled Software Defined Networking: A Comprehensive Overview.&quot; (2018). <a href="https://arxiv.org/abs/1803.06818">https://arxiv.org/abs/1803.06818</a> <a href="#fnref10" class="footnote-backref">↩︎</a> <a href="#fnref10:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn11" class="footnote-item"><p>Usama, Muhammad, et al. &quot;Unsupervised Machine Learning for Networking: Techniques, Applications and Research Challenges.&quot; arXiv preprint arXiv:1709.06599 (2017). <a href="https://arxiv.org/abs/1709.06599">https://arxiv.org/abs/1709.06599</a> <a href="#fnref11" class="footnote-backref">↩︎</a> <a href="#fnref11:1" class="footnote-backref">↩︎</a> <a href="#fnref11:2" class="footnote-backref">↩︎</a> <a href="#fnref11:3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn12" class="footnote-item"><p>Wang, Xiaofei, Xiuhua Li, and Victor CM Leung. &quot;Artificial intelligence-based techniques for emerging heterogeneous network: State of the arts, opportunities, and challenges.&quot; IEEE Access 3 (2015). <a href="https://doi.org/10.1109/ACCESS.2015.2467174">https://doi.org/10.1109/ACCESS.2015.2467174</a> <a href="#fnref12" class="footnote-backref">↩︎</a> <a href="#fnref12:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn13" class="footnote-item"><p>Aliu, Osianoh Glenn, et al. &quot;A survey of self organisation in future cellular networks.&quot; IEEE Communications Surveys &amp; Tutorials 15.1 (2013). <a href="https://doi.org/10.1109/SURV.2012.021312.00116">https://doi.org/10.1109/SURV.2012.021312.00116</a> <a href="#fnref13" class="footnote-backref">↩︎</a> <a href="#fnref13:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn14" class="footnote-item"><p>Boutaba, Raouf, et al. &quot;A comprehensive survey on machine learning for networking: evolution, applications and research opportunities.&quot; Journal of Internet Services and Applications 9.1 (2018). <a href="https://doi.org/10.1186/s13174-018-0087-2">https://doi.org/10.1186/s13174-018-0087-2</a> <a href="#fnref14" class="footnote-backref">↩︎</a> <a href="#fnref14:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn15" class="footnote-item"><p>Qadir, Junaid. &quot;Artificial intelligence based cognitive routing for cognitive radio networks.&quot; Artificial Intelligence Review 45.1 (2016. <a href="https://doi.org/10.1007/s10462-015-9438-6">https://doi.org/10.1007/s10462-015-9438-6</a> <a href="#fnref15" class="footnote-backref">↩︎</a> <a href="#fnref15:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn16" class="footnote-item"><p>Chen, Tao, Rami Bahsoon, and Xin Yao. &quot;A survey and taxonomy of self-aware and self-adaptive cloud autoscaling systems.&quot; ACM Computing Surveys (CSUR) 51.3 (2018): 61. <a href="#fnref16" class="footnote-backref">↩︎</a> <a href="#fnref16:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn17" class="footnote-item"><p>White, Steve R., et al. &quot;An architectural approach to autonomic computing.&quot; Autonomic Computing, 2004. Proceedings. International Conference on. IEEE, 2004. <a href="https://doi.org/10.1109/ICAC.2004.1301340">https://doi.org/10.1109/ICAC.2004.1301340</a> <a href="#fnref17" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn18" class="footnote-item"><p>Nguyen, Thuy TT, and Grenville Armitage. &quot;A survey of techniques for internet traffic classification using machine learning.&quot; IEEE Communications Surveys &amp; Tutorials 10.4 (2008): 56-76. <a href="https://doi.org/10.1109/SURV.2008.080406">https://doi.org/10.1109/SURV.2008.080406</a> <a href="#fnref18" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn19" class="footnote-item"><p>Mao, Hongzi, et al. &quot;Resource management with deep reinforcement learning.&quot; Proceedings of the 15th ACM Workshop on Hot Topics in Networks. ACM, 2016. <a href="https://doi.org/10.1145/3005745.3005750">https://doi.org/10.1145/3005745.3005750</a> <a href="#fnref19" class="footnote-backref">↩︎</a> <a href="#fnref19:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn20" class="footnote-item"><p>Heller, Brandon, et al. &quot;Elastictree: Saving energy in data center networks.&quot; NDSI. Vol. 10. 2010. <a href="https://www.usenix.org/legacy/event/nsdi10/tech/full_papers/heller.pdf">https://www.usenix.org/legacy/event/nsdi10/tech/full_papers/heller.pdf</a> <a href="#fnref20" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn21" class="footnote-item"><p>Zorzi, Michele, et al. &quot;Cognition-based networks: A new perspective on network optimization using learning and distributed intelligence.&quot; IEEE Access 3 (2015): 1512-1530. <a href="https://doi.org/10.1109/ACCESS.2015.2471178">https://doi.org/10.1109/ACCESS.2015.2471178</a> <a href="#fnref21" class="footnote-backref">↩︎</a> <a href="#fnref21:1" class="footnote-backref">↩︎</a> <a href="#fnref21:2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn22" class="footnote-item"><p>Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J.: Distributed representations of words and phrases and their compositionality. NIPS (2013). pp. 3111–3119. <a href="#fnref22" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn23" class="footnote-item"><p>Tsai, Chih-Fong, et al. &quot;Intrusion detection by machine learning: A review.&quot; Expert Systems with Applications 36.10 (2009). <a href="https://doi.org/10.1016/j.eswa.2009.05.029">https://doi.org/10.1016/j.eswa.2009.05.029</a> <a href="#fnref23" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn24" class="footnote-item"><p>Zibin Zheng, Yilei Zhang, and Michael R. Lyu, “Investigating QoS of Real-<br>
World Web Services”, IEEE Transactions on Services Computing , vol.7, no.1, pp.32-39, 2014. <a href="#fnref24" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn25" class="footnote-item"><p>Sony, C. S. L., and Kenjiro Cho. &quot;Traffic data repository at the WIDE project.&quot; Proceedings of USENIX 2000 Annual Technical Conference: FREENIX Track. 2000. <a href="#fnref25" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->]]></content:encoded></item></channel></rss>